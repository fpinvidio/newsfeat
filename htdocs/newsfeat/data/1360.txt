The Berkeley robot was all the more remarkable because it could grab stuff it had never seen before. Mr. Mahler and the rest of the Berkeley team trained the machine by showing it hundreds of purely digital objects, and after that training, it could pick up items that weren’t represented in its digital data set.“We’re learning from simulated models and then applying that to real work,” said Ken Goldberg, the Berkeley professor who oversees the university’s automation lab.The robot was far from perfect, and it could be several years before it is seen outside research labs. Though it was equipped with a suction cup or a parallel gripper — a kind of two-fingered hand — it could reliably handle only so many items. And it could not switch between the cup and the gripper on the fly. But the techniques used to train it represented a fundamental shift in robotics research, a shift that could overhaul not just Amazon’s warehouses but entire industries.Rather than trying to program behavior into their robot — a painstaking task — Mr. Mahler and his team gave it a way of learning tasks on its own. Researchers at places like Northeastern University, Carnegie Mellon University, Google and OpenAI — the artificial intelligence lab founded by Tesla’s chief executive, Elon Musk — are developing similar techniques, and many believe that such machine learning will ultimately allow robots to master a much wider array of tasks, including manufacturing.“This can extend to tasks of assembly and more complex operations,” said Juan Aparicio, head of advanced manufacturing automation at the German industrial giant Siemens, which is helping to fund the research at Berkeley. “That is the road map.”