PhotoIn the summer of 2004, Andy Martin, a colorful Web columnist and sometime Republican candidate for state office, put out a press release announcing his sadness at having to “expose” Barack Obama as a “Muslim who has concealed his religion.” Reporters ignored Martin’s charge, which offered no proof. But the story took root: Martin’s screed bounced about blogs, mutating over the course of a couple years into an e-mail message that suggested the senator is a kind of Muslim Manchurian candidate for the White House.Though news organizations and fact-checking Web sites like Snopes.com have debunked the claim, the story just won’t die. In an NBC/Wall Street Journal poll taken in December, 8 percent of respondents thought Obama was Muslim, half as many as correctly identified him as a Protestant.The Obama-is-a-Muslim rumor does not seem to have hurt the candidate’s fortunes, at least not yet. But the myth’s persistence illustrates a growing cultural vulnerability to rumor. Journalists typically presume that facts matter: show the public what is true, and they will make decisions correctly. Psychologists who study how we separate truth from fiction, however, have demonstrated that the process is not so simple. And because digital technology fosters social networks that are both closely knit and far-flung, rumors are now free to travel widely within certain groups before they meet any opposition from the truth.Consider, for starters, this paradox of social psychology, a problem for myth busters everywhere: repeating a claim, even if only to refute it, increases its apparent truthfulness. In 2003, the psychologist Ian Skurnik and several of his colleagues asked senior citizens to sit through a computer presentation of a series of health warnings that were randomly identified as either true or false — for example, “Aspirin destroys tooth enamel” (true) or “Corn chips contain twice as much fat as potato chips” (false). A few days later, they quizzed the seniors on what they had learned.Advertisement Continue reading the main storyThe psychologists expected that seniors would mistakenly remember some false statements as true. What was remarkable, though, was which claims they most often got wrong — the ones they had been exposed to multiple times. In other words, the more that researchers had stressed that a given warning was false, the more likely seniors were to eventually come to believe it was true. (College students in the study did not make the same mistakes.)Newsletter Sign Up Continue reading the main story Please verify you're not a robot by clicking the box. Invalid email address. Please re-enter. You must select a newsletter to subscribe to. Sign Up You will receive emails containing news content , updates and promotions from The New York Times. You may opt-out at any time. You agree to receive occasional updates and special offers for The New York Times's products and services. Thank you for subscribing. An error has occurred. Please try again later. View all New York Times newsletters.To understand this turnabout, says Norbert Schwarz, a psychologist at the University of Michigan who worked with Skurnik on the study, it helps to know how our brains suss out truth from fiction. To determine the veracity of a given statement, we often look to society’s collective assessment of it. But it is difficult to measure social consensus very precisely, and our brains rely, instead, upon a sensation of familiarity with an idea. You use a rule of thumb: if something seems familiar, you must have heard it before, and if you’ve heard it before, it must be true.