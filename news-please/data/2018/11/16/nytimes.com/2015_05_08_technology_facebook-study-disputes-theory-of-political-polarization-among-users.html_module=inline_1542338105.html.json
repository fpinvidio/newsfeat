{"authors": ["Farhad Manjoo"], "date_download": "2018-11-16 03:15:05", "date_modify": "2018-11-16 03:15:05", "date_publish": "2015-05-07 18:00:19", "description": "Almost 29 percent of the news stories displayed by Facebook’s News Feed present views that conflict with the user’s own ideology, the study found.", "filename": "2015_05_08_technology_facebook-study-disputes-theory-of-political-polarization-among-users.html_module=inline_1542338105.html", "image_url": "https://static01.nyt.com/images/2015/05/08/business/08FACEBOOK/08FACEBOOK-facebookJumbo.jpg", "language": "en", "localpath": "/Users/federicoperezinvidio/Projects/illinois/newsfeat/news-please//data/2018/11/16/nytimes.com/2015_05_08_technology_facebook-study-disputes-theory-of-political-polarization-among-users.html_module=inline_1542338105.html", "title": "Facebook Use Polarizing? Site Begs to Differ", "title_page": "Facebook Use Polarizing? Site Begs to Differ - The New York Times", "title_rss": "NULL", "source_domain": "nytimes.com", "text": "The findings are convenient for Facebook. With more than 1.3 billion users, the social network is effectively the world’s most widely read daily newspaper. About 30 percent of American adults get their news from Facebook, according to the Pew Research Center. But its editorial decisions are drafted with little transparency using the News Feed algorithm. Facebook could use the study’s results to show that the algorithm is not ruining national discourse.\nFacebook said its researchers had wide latitude to pursue their research interests and to present whatever they found. The results were reviewed before publication in Science, with the journal selecting an anonymous panel of scholars unaffiliated with Facebook. Science does not disclose the identity of experts and warns reviewers to declare any financial ties that might be perceived as a conflict of interest with the study being reviewed.\nFacebook also noted that this study was substantively different from one that caused an outcry last year, in which the company’s scientists altered the number of positive and negative posts that some people saw to examine the effects on mood. This study did not involve an experiment that changed users’ experience of Facebook; researchers analyzed how people use Facebook as it stands today.\nFor Facebook’s study, researchers first determined the point of view of a given article by looking at whether liberals or conservatives had shared it most. They found unsurprising partisan attitudes about some news sources, with Fox News stories shared mainly by conservatives and Huffington Post articles shared by liberals.\nThen they measured how often feeds of users, whose identifying details had been taken out, displayed stories that conflicted with their professed ideologies, and how often they clicked on those stories.\nSome academics said Facebook was always tweaking the News Feed and could easily make changes that would create a more sealed echo chamber.\n“A small effect today might become a large effect tomorrow,” David Lazer, a political scientist at Northeastern University who studies social networks, wrote in a commentary on the Facebook study also published in Science. “The deliberative sky is not yet falling, but the skies are not completely clear either.”", "url": "https://www.nytimes.com/2015/05/08/technology/facebook-study-disputes-theory-of-political-polarization-among-users.html?module=inline"}